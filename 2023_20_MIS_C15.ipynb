{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIS: Clase 15 (2023-20)\n",
    "\n",
    "El objetivo de esta clase es explicar los algoritmos que se pidió implementar la clase pasada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue de paquetes\n",
    "import numpy as np\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generador de agentes\n",
    "def agentes(n:int,restricciones:list=1):\n",
    "    if isinstance(restricciones,int):\n",
    "        A = {\"A_{}\".format(i):restricciones for i in range(n)}\n",
    "    elif isinstance(restricciones,list):\n",
    "        if len(restricciones)==n:\n",
    "            A = {\"A_{}\".format(i):restricciones[i] for i in range(n)}\n",
    "        else:\n",
    "            raise Exception(\"Introduzca Parámetros Adecuados\") \n",
    "    return A\n",
    "    \n",
    "# Generador de objetos\n",
    "def objetos(m:int):\n",
    "    return [\"O_{}\".format(i) for i in range(m)]\n",
    "\n",
    "# Generador de preferencias\n",
    "def preferencias(agentes:dict,objetos:list):\n",
    "    pref = {}\n",
    "    for agente in agentes:\n",
    "        obj = copy.deepcopy(objetos)\n",
    "        cont = 0\n",
    "        n=len(obj)\n",
    "        arreglo = {}\n",
    "        arreglo1 = {}\n",
    "        while 0<n:\n",
    "            i = random.randint(0,n-1)\n",
    "            U = obj.pop(i)\n",
    "            arreglo[cont] = U\n",
    "            arreglo1[U]=cont\n",
    "            n -= 1\n",
    "            cont += 1\n",
    "        pref[agente] = (arreglo,arreglo1,agentes[agente]) #Retorna la relación Objeto-Posición, Posición-Objeto y la cantidad de objetos que puede tener el agente\n",
    "    return pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplos de Prueba\n",
    "Agentes = agentes(3,2)\n",
    "Objetos = objetos(5)\n",
    "Preferencias = preferencias(Agentes,Objetos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictadores Seriales 1:1 y m:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dict_Serial_1_1(Agentes,Objetos,Preferencias,aleatorio=False):\n",
    "    AAA = list(Agentes.keys()) #Obtengo Agentes\n",
    "    if aleatorio:\n",
    "        random.shuffle(AAA) # Hago aleatorio el orden de elección\n",
    "    Asignaciones = {obj:False for obj in Objetos} # Inicializo las asiganciones\n",
    "    for pos in range(len(AAA)): # Recorro las posiciones de los agentes\n",
    "        agent = AAA[pos] # Obtengo el agente que va en este turno\n",
    "        Pref = Preferencias[agent][0] # Obtengo las preferencias de los agentes\n",
    "        for j in Pref: # Recorro el orden de preferencias \n",
    "            Obj = Pref[j]\n",
    "            if Asignaciones[Obj]==False:\n",
    "                Asignaciones[Obj]=agent\n",
    "                break\n",
    "    return Asignaciones # Retorno asignaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dict_Serial_m_1(Agentes,Objetos,Preferencias,aleatorio=False):\n",
    "    AAA = list(Agentes.keys()) #Obtengo Agentes\n",
    "    if aleatorio:\n",
    "        random.shuffle(AAA) # Hago aleatorio el orden de elección\n",
    "    Ag = copy.deepcopy(Agentes)\n",
    "    Asignaciones = {obj:False for obj in Objetos} # Inicializo las asiganciones\n",
    "    for pos in range(len(AAA)): # Recorro las posiciones de los agentes\n",
    "        agent = AAA[pos] # Obtengo el agente que va en este turno\n",
    "        Pref = Preferencias[agent][0] # Obtengo las preferencias de los agentes\n",
    "        for j in Pref: # Recorro el orden de preferencias \n",
    "            if Ag[agent]>0:# Reviso si es posible hacer una asignación\n",
    "                Obj = Pref[j] # Tomo el objeto\n",
    "                if Asignaciones[Obj]==False: # Reviso si no está asignado\n",
    "                    Asignaciones[Obj]=agent # Asigno\n",
    "                    Ag[agent] = Ag[agent]-1 # Actualizo el cupo de objetos que el agente tiene disponible\n",
    "            else:\n",
    "                break # Dejo de buscar asignaciones para este agente si ya tiene su cupo completo\n",
    "    return Asignaciones # Retorno asignaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O_0': False, 'O_1': False, 'O_2': 'A_1', 'O_3': 'A_0', 'O_4': 'A_2'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_Serial_1_1(Agentes,Objetos,Preferencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O_0': 'A_1', 'O_1': 'A_2', 'O_2': 'A_1', 'O_3': 'A_0', 'O_4': 'A_0'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_Serial_m_1(Agentes,Objetos,Preferencias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictadores Seriales Inversos 1:1 y m:1. (Ley de la Selva)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para estos modelos, hay que hacer unas funciones auxiliares antes.\n",
    "def llave_dado_valor(diccionario,valor):\n",
    "    key = list(filter(lambda x: diccionario[x] == valor, diccionario))[0]\n",
    "    return key\n",
    "\n",
    "def asignador_forzoso(Preferencias,Agentes,agente_despojado,asignaciones,orden_fuerza):\n",
    "    pos = llave_dado_valor(orden_fuerza,agente_despojado) #Encuentro la fuerza del agente despojado\n",
    "    Agentes[agente_despojado] = Agentes[agente_despojado]+1 # Hago evidente que al haberle quitado un objeto al agente, su cupo incrementa en uno\n",
    "    Pref = Preferencias[agente_despojado][0] # Obtengo las preferencias del agente despojado\n",
    "    for j in Pref: # Recorro el orden de preferencias \n",
    "        Obj = Pref[j] # Tomo el objeto a asignar\n",
    "        if asignaciones[Obj]==False: # Si no ha sido asignado, asigno\n",
    "            asignaciones[Obj]=agente_despojado # Asigno\n",
    "            Agentes[agente_despojado] = Agentes[agente_despojado]-1 # Actualizo el cupo de objetos del agente\n",
    "            break\n",
    "        elif pos<llave_dado_valor(orden_fuerza,asignaciones[Obj]): # Reviso si el agente puede usar fuerza\n",
    "            agente_despojado1 = asignaciones[Obj] # Identifico al agente que le voy a quitar su objeto\n",
    "            asignaciones[Obj] = agente_despojado # Asigno el objeto al agente\n",
    "            Agentes[agente_despojado] = Agentes[agente_despojado]-1 # Actualizo el cupo del agente\n",
    "            asignaciones,Agentes = asignador_forzoso(Preferencias,Agentes,agente_despojado1,asignaciones,orden_fuerza) # Realizo el proceso de asignación al agente despojado\n",
    "            break\n",
    "    return asignaciones,Agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dict_Serial_Inverso_1_1(Agentes,Objetos,Preferencias,aleatorio=False):\n",
    "    AAA = list(Agentes.keys()) #Obtengo Agentes\n",
    "    if aleatorio:\n",
    "        random.shuffle(AAA) # Hago aleatorio el orden de elección\n",
    "    AAA = {i:AAA[i] for i in range(len(AAA))} # Hago explicita la relación agente-orden(fuerza)\n",
    "    Ag = copy.deepcopy(Agentes)\n",
    "    Asignaciones = {obj:False for obj in Objetos} # Inicializo las asiganciones\n",
    "    pos = len(AAA)-1 # Inicializo la posición final, i.e. inicio por el agente más débil.\n",
    "    while pos>=0: # Recorro las posiciones de los agentes\n",
    "        agent = AAA[pos] # Obtengo el agente que va en este turno\n",
    "        Pref = Preferencias[agent][0] # Obtengo las preferencias de los agentes\n",
    "        for j in Pref: # Recorro el orden de preferencias \n",
    "            Obj = Pref[j] # Tomo el objeto a asignar\n",
    "            if Asignaciones[Obj]==False: # Si no ha sido asignado, asigno\n",
    "                Asignaciones[Obj]=agent\n",
    "                break\n",
    "            elif llave_dado_valor(AAA,agent)<llave_dado_valor(AAA,Asignaciones[Obj]): # Reviso si el agente puede usar fuerza (piense por qué esta condición siempre se cumple)\n",
    "                agent_despojado = Asignaciones[Obj] # Identifico al agente que le voy a quitar su objeto\n",
    "                Asignaciones[Obj]=agent # Asigno el objeto al agente\n",
    "                Asignaciones,Ag = asignador_forzoso(Preferencias,Ag,agent_despojado,Asignaciones,AAA)# Realizo el proceso de asignación al agente despojado\n",
    "                break\n",
    "        pos-=1 # Paso al siguiente agente en la lista\n",
    "    return Asignaciones # Retorno asignaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dict_Serial_Inverso_m_1(Agentes,Objetos,Preferencias,aleatorio=False):\n",
    "    AAA = list(Agentes.keys()) #Obtengo Agentes\n",
    "    if aleatorio:\n",
    "        random.shuffle(AAA) # Hago aleatorio el orden de elección\n",
    "    AAA = {i:AAA[i] for i in range(len(AAA))} # Hago explicita la relación agente-orden(fuerza)\n",
    "    Ag = copy.deepcopy(Agentes)\n",
    "    Asignaciones = {obj:False for obj in Objetos} # Inicializo las asiganciones\n",
    "    pos = len(AAA)-1 # Inicializo la posición final, i.e. inicio por el agente más débil.\n",
    "    while pos>=0: # Recorro las posiciones de los agentes\n",
    "        agent = AAA[pos] # Obtengo el agente que va en este turno\n",
    "        Pref = Preferencias[agent][0] # Obtengo las preferencias de los agentes\n",
    "        for j in Pref: # Recorro el orden de preferencias \n",
    "            if Ag[agent]>0: # Reviso si es posible hacer asignación al agente\n",
    "                Obj = Pref[j] # Tomo el objeto a asignar\n",
    "                if Asignaciones[Obj]==False: # Si no ha sido asignado, asigno\n",
    "                    Asignaciones[Obj]=agent # Asigno\n",
    "                    Ag[agent] = Ag[agent]-1 # Actualizo el cupo de objetos del agente\n",
    "                elif llave_dado_valor(AAA,agent)<llave_dado_valor(AAA,Asignaciones[Obj]): # Reviso si el agente puede usar fuerza (piense por qué esta condición siempre se cumple)\n",
    "                    agent_despojado = Asignaciones[Obj] # Identifico al agente que le voy a quitar su objeto\n",
    "                    Asignaciones[Obj]=agent # Asigno el objeto al agente\n",
    "                    Ag[agent] = Ag[agent]-1 # Actualizo el cupo de objetos del agente\n",
    "                    Asignaciones,Ag = asignador_forzoso(Preferencias,Ag,agent_despojado,Asignaciones,AAA)# Realizo el proceso de asignación al agente despojado\n",
    "            else:\n",
    "                break # Dejo de buscar asignaciones para este agente.\n",
    "        pos-=1 # Paso al siguiente agente en la lista\n",
    "    return Asignaciones # Retorno asignaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O_0': False, 'O_1': False, 'O_2': 'A_1', 'O_3': 'A_0', 'O_4': 'A_2'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_Serial_Inverso_1_1(Agentes,Objetos,Preferencias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O_0': 'A_1', 'O_1': 'A_2', 'O_2': 'A_1', 'O_3': 'A_0', 'O_4': 'A_0'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dict_Serial_Inverso_m_1(Agentes,Objetos,Preferencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tarea:\n",
    "\n",
    "1. Entienda por qué Dictador Serial y Dictador Serial inverso (1:1 y m:1) tienen los mismos resultados\n",
    "\n",
    "2. Piense una forma (no computacionalmente eficiente), pero sencilla de implementar en código el algoritmo de TTC."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
